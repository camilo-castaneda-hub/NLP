{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperación ranqueada y vectorización de documentos (RRDV) usando GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\57305\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\57305\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\57305\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.11.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\57305\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (6.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/77/85/bff3a1e818ec6aa3dd466ff4f4b0a727db9fdb41f2e849747ad902ddbe95/scikit_learn-1.3.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\57305\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\57305\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\57305\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/9.2 MB 1.8 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.1/9.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.8/9.2 MB 17.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.4/9.2 MB 21.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/9.2 MB 24.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.7/9.2 MB 25.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 26.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 26.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 22.6 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.0 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import nltk\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora, models, similarities  # Importar Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths to the compressed files and the target directory\n",
    "compressed_files = ['docs-raw-texts.zip', 'queries-raw-texts.zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracción completada\n"
     ]
    }
   ],
   "source": [
    "# Extract files from each compressed file\n",
    "for compressed_file in compressed_files:\n",
    "    with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
    "        folder_name = os.path.splitext(compressed_file)[0]  # Remove the \".zip\" extension\n",
    "        target_folder = os.path.join(folder_name)\n",
    "        \n",
    "        if not os.path.exists(target_folder):\n",
    "            # Create the folder within the target directory\n",
    "            os.mkdir(target_folder)\n",
    "        \n",
    "            # Extract all files to the target folder\n",
    "            zip_ref.extractall(target_folder)\n",
    "\n",
    "print(\"Extracción completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios que contienen los archivos necesarios, cambiar acá si es necesario\n",
    "xml_files_directory = 'docs-raw-texts'\n",
    "\n",
    "relevance_judgments_directory = \"relevance-judgments.tsv\"\n",
    "\n",
    "queries_directory = \"queries-raw-texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK setup\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def extract_raw_text(xml_path: str, title: bool = False) -> str:\n",
    "    \"\"\"Extrae el texto sin procesar de un archivo .naf.\n",
    "\n",
    "    Args:\n",
    "        xml_path (str): La ruta al archivo .naf.\n",
    "        title (bool): Si es True, el título del documento también se agrega al texto extraído.\n",
    "\n",
    "    Returns:\n",
    "        Str: El texto sin procesar del archivo .naf.\n",
    "    \"\"\"\n",
    "    if title:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        # Extract content from the XML\n",
    "        return root.find(\".//nafHeader/fileDesc\").get(\"title\") + \", \" + root.find('raw').text  # Añade título cuando se especifíca\n",
    "    else:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        # Extract content from the XML\n",
    "        return root.find('raw').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de preprocesamiento, se usará para todos los inputs al modelo (queries y documentos)\n",
    "def preprocess_text(text: str) -> list[str]:\n",
    "    \"\"\"Preprocesa un texto para eliminar palabras vacías, aplicar stemming y convertir a minúsculas.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto a preprocesar.\n",
    "\n",
    "    Returns:\n",
    "        List: Una lista con las palabras del texto preprocesado.\n",
    "    \"\"\"\n",
    "    text = text.strip().lower()  # Normalización del texto, todo en minúscula y se quitan espacios innecesarios.\n",
    "    tokens = tokenizer.tokenize(text)  # Tokenización por espacio\n",
    "    \n",
    "    # Usar Gensim para aplicar PorterStemmer y eliminar stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Eliminar stopwords\n",
    "    stemmer = PorterStemmer()  # Utilizar PorterStemmer de Gensim\n",
    "    tokens = stemmer.stem_documents(tokens)  # Aplicar PorterStemmer\n",
    "    return tokens  # Retorna lista con el texto preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted index created.\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the inverted index (term -> list of documents)\n",
    "inverted_index = {}\n",
    "\n",
    "# Dictionary to store term frequencies per document (term -> {document: frequency})\n",
    "term_freq_per_document = {}\n",
    "\n",
    "# Iterate over XML files in the directory\n",
    "for filename in os.listdir(xml_files_directory):\n",
    "    if filename.endswith('.naf'):\n",
    "        xml_path = os.path.join(xml_files_directory, filename)\n",
    "        content = extract_raw_text(xml_path, title=True)\n",
    "        # Preprocess the content\n",
    "        preprocessed_tokens = preprocess_text(content)\n",
    "        \n",
    "        # Create the inverted index and update term frequencies per document\n",
    "        for term in preprocessed_tokens:\n",
    "            if term in inverted_index:\n",
    "                if filename not in inverted_index[term]:\n",
    "                    inverted_index[term].append(filename)\n",
    "            else:\n",
    "                inverted_index[term] = [filename]\n",
    "            \n",
    "            if term in term_freq_per_document:\n",
    "                if filename in term_freq_per_document[term]:\n",
    "                    term_freq_per_document[term][filename] += 1\n",
    "                else:\n",
    "                    term_freq_per_document[term][filename] = 1\n",
    "            else:\n",
    "                term_freq_per_document[term] = {filename: 1}\n",
    "\n",
    "print(\"Inverted index created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario de corpora y un modelo TF-IDF usando Gensim\n",
    "documents = [preprocess_text(extract_raw_text(os.path.join(xml_files_directory, filename), title=True)) for filename in os.listdir(xml_files_directory) if filename.endswith('.naf')]\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(query_string):\n",
    "    # Unir los términos de la lista en una cadena\n",
    "    query_string = ' '.join(query_string)\n",
    "    query_terms = preprocess_text(query_string)\n",
    "    return {term: query_terms.count(term) for term in query_terms}\n",
    "\n",
    "# Function to calculate TF-IDF vector for a query\n",
    "def calculate_tfidf_vector(input, dictionary, tfidf_model):\n",
    "    query = preprocess_input(input)\n",
    "    query_bow = dictionary.doc2bow(query)\n",
    "    tfidf_vector = tfidf_model[query_bow]\n",
    "    return tfidf_vector\n",
    "\n",
    "# Function to calculate cosine similarity between two vectors\n",
    "def calculate_cosine_similarity(vector1, vector2):\n",
    "    index = similarities.SparseMatrixSimilarity([vector1], num_features=len(vector1))\n",
    "    similarity = index[vector2]\n",
    "    return similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve and rank documents based on cosine similarity scores\n",
    "def retrieve_and_rank_documents(query_string, dictionary, tfidf_model):\n",
    "    similarity_scores = {}  # Dictionary to store cosine similarity scores\n",
    "    query_vector = calculate_tfidf_vector(query_string, dictionary, tfidf_model)\n",
    "    \n",
    "    for document in os.listdir(xml_files_directory):\n",
    "        if document.endswith('.naf'):\n",
    "            document_path = os.path.join(xml_files_directory, document)\n",
    "            document_text = preprocess_text(extract_raw_text(document_path, title=True))\n",
    "            document_vector = calculate_tfidf_vector(document_text, dictionary, tfidf_model)\n",
    "            similarity = calculate_cosine_similarity(query_vector, document_vector)\n",
    "            \n",
    "            if similarity > 0:\n",
    "                similarity_scores[document[:-4]] = similarity  # Remove the \".naf\" extension\n",
    "    \n",
    "    ranked_documents = sorted(similarity_scores.keys(), key=lambda doc: similarity_scores[doc], reverse=True)\n",
    "    return ranked_documents, similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "output_filename = \"GENSIM-consultas_resultados.tsv\"\n",
    "\n",
    "if os.path.exists(output_filename):\n",
    "    print(\"Results in {} already exist\".format(output_filename))\n",
    "else:\n",
    "    # Write results to file\n",
    "    results_file = open(output_filename, \"w\")\n",
    "\n",
    "    # Iterate over queries\n",
    "    for query_file in os.listdir(queries_directory):\n",
    "        if query_file.endswith('.naf'):\n",
    "            query_path = os.path.join(queries_directory, query_file)\n",
    "            query_text = preprocess_text(extract_raw_text(query_path))\n",
    "            \n",
    "            ranked_documents, similarity_scores = retrieve_and_rank_documents(query_text, dictionary, tfidf)\n",
    "            \n",
    "            # Write results to the file\n",
    "            result_line = query_file[8:-4] + \"\\t\" + \",\".join([f\"{doc[8:]}:{similarity_scores[doc]:.6f}\" for doc in ranked_documents])\n",
    "            results_file.write(result_line + \"\\n\")\n",
    "            print(\"finished query {}\".format(query_file))\n",
    "\n",
    "    results_file.close()\n",
    "    print(\"Results written to \" + output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics from sklearn\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Load the relevance judgments from the file\n",
    "relevance_judgments_file = open(relevance_judgments_directory, \"r\")\n",
    "relevance_judgments = {}\n",
    "\n",
    "for line in relevance_judgments_file:\n",
    "    query, judgments = line.strip().split('\\t')\n",
    "    relevance_judgments[query] = judgments.split(',')\n",
    "\n",
    "relevance_judgments_file.close()\n",
    "\n",
    "# Load the query results from the file\n",
    "query_results_file = open(\"GENSIM-consultas_resultados.tsv\", \"r\")\n",
    "query_results = {}\n",
    "\n",
    "for line in query_results_file:\n",
    "    query, results = line.strip().split('\\t')\n",
    "    query_results[query] = results.split(',')\n",
    "\n",
    "query_results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate Precision at K\n",
    "def precision_at_k(k, query, query_results, relevance_judgments):\n",
    "    top_k_results = query_results[query][:k]\n",
    "    relevant_documents = set(relevance_judgments[query])\n",
    "    retrieved_documents = set(top_k_results)\n",
    "    relevant_and_retrieved = relevant_documents.intersection(retrieved_documents)\n",
    "    \n",
    "    return len(relevant_and_retrieved) / k\n",
    "\n",
    "# Define function to calculate Recall at K\n",
    "def recall_at_k(k, query, query_results, relevance_judgments):\n",
    "    top_k_results = query_results[query][:k]\n",
    "    relevant_documents = set(relevance_judgments[query])\n",
    "    retrieved_documents = set(top_k_results)\n",
    "    relevant_and_retrieved = relevant_documents.intersection(retrieved_documents)\n",
    "    \n",
    "    return len(relevant_and_retrieved) / len(relevant_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision and Recall at K\n",
    "k_values = [1, 3, 5, 10]\n",
    "for k in k_values:\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for query in query_results:\n",
    "        if query in relevance_judgments:\n",
    "            precision = precision_at_k(k, query, query_results, relevance_judgments)\n",
    "            recall = recall_at_k(k, query, query_results, relevance_judgments)\n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "\n",
    "    if len(precision_scores) > 0:\n",
    "        mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "    else:\n",
    "        mean_precision = 0.0\n",
    "\n",
    "    if len(recall_scores) > 0:\n",
    "        mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "    else:\n",
    "        mean_recall = 0.0\n",
    "\n",
    "    print(f\"Precision@{k}: {mean_precision:.4f}\")\n",
    "    print(f\"Recall@{k}: {mean_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate NDCG at K\n",
    "def ndcg_at_k(k, query, query_results, relevance_judgments):\n",
    "    top_k_results = query_results[query][:k]\n",
    "    relevance_levels = [1 if doc in relevance_judgments[query] else 0 for doc in top_k_results]\n",
    "    \n",
    "    # Calculate DCG\n",
    "    dcg = relevance_levels[0]\n",
    "    for i in range(1, k):\n",
    "        dcg += relevance_levels[i] / np.log2(i + 1)\n",
    "    \n",
    "    # Calculate IDCG\n",
    "    ideal_relevance_levels = sorted(relevance_levels, reverse=True)\n",
    "    idcg = ideal_relevance_levels[0]\n",
    "    for i in range(1, k):\n",
    "        idcg += ideal_relevance_levels[i] / np.log2(i + 1)\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dcg / idcg\n",
    "\n",
    "# Calculate NDCG at K\n",
    "k_values = [1, 3, 5, 10]\n",
    "for k in k_values:\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for query in query_results:\n",
    "        if query in relevance_judgments:\n",
    "            ndcg = ndcg_at_k(k, query, query_results, relevance_judgments)\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "    if len(ndcg_scores) > 0:\n",
    "        mean_ndcg = sum(ndcg_scores) / len(ndcg_scores)\n",
    "    else:\n",
    "        mean_ndcg = 0.0\n",
    "\n",
    "    print(f\"NDCG@{k}: {mean_ndcg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anteia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
